{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture.\n",
    "\n",
    "We might want to compete, and hence might be looking for any way to win. Hence lets explore the sample dataset of jeopardy questions(i.e. the first 20,000 rows of the full data set of Jeopardy questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeopardy Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = pd.read_csv('jeopardy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date      Round                         Category  \\\n",
       "0             4680  2004-12-31  Jeopardy!                          HISTORY   \n",
       "1             4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2             4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3             4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4             4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...            ...         ...        ...                              ...   \n",
       "19994         3582  2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995         3582  2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996         3582  2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997         3582  2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998         3582  2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "       Value                                           Question  \\\n",
       "0       $200  For the last 8 years of his life, Galileo was ...   \n",
       "1       $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2       $200  The city of Yuma in this state has a record av...   \n",
       "3       $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4       $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...      ...                                                ...   \n",
       "19994   $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995   $200                      ...& the New Power Generation   \n",
       "19996   $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997   $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998   $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer  \n",
       "0           Copernicus  \n",
       "1           Jim Thorpe  \n",
       "2              Arizona  \n",
       "3           McDonald's  \n",
       "4           John Adams  \n",
       "...                ...  \n",
       "19994               18  \n",
       "19995           Prince  \n",
       "19996          Galileo  \n",
       "19997  Monica Lewinsky  \n",
       "19998           Camels  \n",
       "\n",
       "[19999 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "* `Show Number` - the Jeopardy episode number\n",
    "* `Air Date` - the date the episode aired\n",
    "* `Round` - the round of Jeopardy\n",
    "* `Category` - the category of the question\n",
    "* `Value` - the number of dollars the correct answer is worth\n",
    "* `Question` - the text of the question\n",
    "* `Answer` - the text of the answer\n",
    "\n",
    "Each episode is a Jeopardy game consisting of rounds in which questions are asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns = jeopardy.columns.str.strip()\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns information and formattting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1   Air Date     19999 non-null  object\n",
      " 2   Round        19999 non-null  object\n",
      " 3   Category     19999 non-null  object\n",
      " 4   Value        19999 non-null  object\n",
      " 5   Question     19999 non-null  object\n",
      " 6   Answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The text columns need to be standardized\n",
    "* The `Value` column should be numeric, to allow us to manipulate it easier.\n",
    "* The `Air Date` column should also be a datetime, not a string, to enable us to work with it easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to normalize all of the text columns (the Question and Answer columns) to ensure that we put words in lowercase and remove punctuation so \"Don't\" and \"don't\" aren't considered to be different words when we compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question           Answer\n",
       "0      For the last 8 years of his life, Galileo was ...       Copernicus\n",
       "1      No. 2: 1912 Olympian; football star at Carlisl...       Jim Thorpe\n",
       "2      The city of Yuma in this state has a record av...          Arizona\n",
       "3      In 1963, live on \"The Art Linkletter Show\", th...       McDonald's\n",
       "4      Signer of the Dec. of Indep., framer of the Co...       John Adams\n",
       "...                                                  ...              ...\n",
       "19994  Of 8, 12 or 18, the number of U.S. states that...               18\n",
       "19995                      ...& the New Power Generation           Prince\n",
       "19996  In 1589 he was appointed professor of mathemat...          Galileo\n",
       "19997  Before the grand jury she said, \"I'm really so...  Monica Lewinsky\n",
       "19998  Llamas are the heftiest South American members...           Camels\n",
       "\n",
       "[19999 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[['Question','Answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(qa_text):\n",
    "    normalized_text = qa_text.lower()\n",
    "    #remove punctuation marks\n",
    "    normalized_text = re.sub('[^a-zA-Z0-9\\s]','',normalized_text)\n",
    "    #remove extra spaces\n",
    "    normalized_text = re.sub('\\s+',' ',normalized_text)\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        for the last 8 years of his life galileo was u...\n",
       "1        no 2 1912 olympian football star at carlisle i...\n",
       "2        the city of yuma in this state has a record av...\n",
       "3        in 1963 live on the art linkletter show this c...\n",
       "4        signer of the dec of indep framer of the const...\n",
       "                               ...                        \n",
       "19994    of 8 12 or 18 the number of us states that tou...\n",
       "19995                             the new power generation\n",
       "19996    in 1589 he was appointed professor of mathemat...\n",
       "19997    before the grand jury she said im really sorry...\n",
       "19998    llamas are the heftiest south american members...\n",
       "Name: clean_question, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             copernicus\n",
       "1             jim thorpe\n",
       "2                arizona\n",
       "3              mcdonalds\n",
       "4             john adams\n",
       "              ...       \n",
       "19994                 18\n",
       "19995             prince\n",
       "19996            galileo\n",
       "19997    monica lewinsky\n",
       "19998             camels\n",
       "Name: clean_answer, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n",
    "jeopardy['clean_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the `Value` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$200', '$400', '$600', '$800', '$2,000', '$1000', '$1200',\n",
       "       '$1600', '$2000', '$3,200', 'None', '$5,000', '$100', '$300',\n",
       "       '$500', '$1,000', '$1,500', '$1,200', '$4,800', '$1,800', '$1,100',\n",
       "       '$2,200', '$3,400', '$3,000', '$4,000', '$1,600', '$6,800',\n",
       "       '$1,900', '$3,100', '$700', '$1,400', '$2,800', '$8,000', '$6,000',\n",
       "       '$2,400', '$12,000', '$3,800', '$2,500', '$6,200', '$10,000',\n",
       "       '$7,000', '$1,492', '$7,400', '$1,300', '$7,200', '$2,600',\n",
       "       '$3,300', '$5,400', '$4,500', '$2,100', '$900', '$3,600', '$2,127',\n",
       "       '$367', '$4,400', '$3,500', '$2,900', '$3,900', '$4,100', '$4,600',\n",
       "       '$10,800', '$2,300', '$5,600', '$1,111', '$8,200', '$5,800',\n",
       "       '$750', '$7,500', '$1,700', '$9,000', '$6,100', '$1,020', '$4,700',\n",
       "       '$2,021', '$5,200', '$3,389'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['Value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(dollar_string):\n",
    "    if dollar_string == 'None':\n",
    "        normalized_value = 0\n",
    "    else:\n",
    "        normalized_value = int(re.sub('[$,]','',dollar_string))\n",
    "    return normalized_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        200\n",
       "1        200\n",
       "2        200\n",
       "3        200\n",
       "4        200\n",
       "        ... \n",
       "19994    200\n",
       "19995    200\n",
       "19996    200\n",
       "19997    200\n",
       "19998    200\n",
       "Name: clean_value, Length: 19999, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_value)\n",
    "jeopardy['clean_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalzing the `Air Date` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2004-12-31\n",
       "1       2004-12-31\n",
       "2       2004-12-31\n",
       "3       2004-12-31\n",
       "4       2004-12-31\n",
       "           ...    \n",
       "19994   2000-03-14\n",
       "19995   2000-03-14\n",
       "19996   2000-03-14\n",
       "19997   2000-03-14\n",
       "19998   2000-03-14\n",
       "Name: Air Date, Length: 19999, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])\n",
    "jeopardy['Air Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "* How often the answer can be used for a question.\n",
    "   - we can answer this by seeing how many times words in the answer also occur in the question. \n",
    "* How often questions are repeated.\n",
    "   - we can answer this by seeing how often complex words (> 6 characters) reoccur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers in Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_answer_in_question(question_info_row):\n",
    "    split_answer = question_info_row['clean_answer'].split()\n",
    "    split_question = question_info_row['clean_question'].split()\n",
    "    \n",
    "    proportion_of_answer_word_in_q_to_num_answer_words = 0\n",
    "    match_count = 0\n",
    "    \n",
    "    #'the' word is commonly found in answers and questions, but doesn't have any meaningful use in finding the answer\n",
    "    #so, remove occurences of 'the' in split_answer cell\n",
    "    split_answer = [word for word in split_answer if word != 'the']\n",
    "    \n",
    "    #prevents a division by zero error later\n",
    "    if len(split_answer) == 0:\n",
    "        return proportion_of_answer_word_in_q_to_num_answer_words\n",
    "    \n",
    "    for answer_word in split_answer:\n",
    "        if answer_word in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    proportion_of_answer_word_in_q_to_num_answer_words = match_count/len(split_answer)\n",
    "    return proportion_of_answer_word_in_q_to_num_answer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "19994    1.0\n",
       "19995    0.0\n",
       "19996    0.0\n",
       "19997    0.0\n",
       "19998    0.0\n",
       "Name: answer_in_question, Length: 19999, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'] = jeopardy.apply(calculate_answer_in_question,axis=1)\n",
    "jeopardy['answer_in_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058347444789267004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On an average, only about 6% of words in an answer occur in a question, hence we probably can't just hope that hearing a question will enable us to figure out the answer. We'll probably have to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recycled Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_overlap = list()\n",
    "terms_used = set()\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [word for word in split_question if len(word) >= 6]\n",
    "    \n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(word)\n",
    "    \n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    \n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy['question_overlap'] = question_overlap    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894031359073217"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about 70% overlap between terms in new questions and terms in old questions. This only looks at a small set of questions, and it doesn't look at phrases, it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Value vs High Value Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money when we're on Jeopardy.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_high_value(question_info):\n",
    "    if question_info['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['high_value'] = jeopardy.apply(determine_high_value,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_high_low_occurances(term_used):\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split(' ')\n",
    "        if term_used in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return (high_count,low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (7, 12),\n",
       " (2, 9),\n",
       " (2, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for i in range(10)]\n",
    "\n",
    "observed_expected = list()\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_high_low_occurances(term))\n",
    "    \n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Chi-squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.3995960878537224, pvalue=0.12136658322360773),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=0.6202349255189139, pvalue=0.4309599995797433),\n",
       " Power_divergenceResult(statistic=0.5918326368236639, pvalue=0.44171132316120576),\n",
       " Power_divergenceResult(statistic=4.97558423439135, pvalue=0.025707519787911092),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.42281054506129573, pvalue=0.515537958129453)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "high_value_count = jeopardy.loc[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy.loc[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = list()\n",
    "\n",
    "for observed in observed_expected:\n",
    "    total_observed_count = sum(observed)\n",
    "    \n",
    "    #calculating expected_high_value_count\n",
    "    expected_high_value_proportion = float(high_value_count)/jeopardy.shape[0]\n",
    "    expected_high_value_count = expected_high_value_proportion * total_observed_count\n",
    "    \n",
    "    #calculating expected_low_value_count\n",
    "    expected_low_value_proportion = float(low_value_count)/jeopardy.shape[0]\n",
    "    expected_low_value_count = expected_low_value_proportion * total_observed_count\n",
    "\n",
    "    observed_frequencies = np.array([observed[0],observed[1]])\n",
    "    expected_frequencies = np.array([expected_high_value_count,expected_low_value_count])\n",
    "    \n",
    "    chi_squared.append(chisquare(observed_frequencies,expected_frequencies))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-squared results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
